#import sys
#import os
# sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from nltk.tokenize import WordPunctTokenizer
from lib.features import FeatureBuilder


class CorpusBuilder:

    def __init__(self):
        self.fb = FeatureBuilder()

    def training(self, filename):
        """ Generate a training file (file_basename.trn) in data/ directory. In the training set,
        labels are generated by a provided annotation file (file_basename.ann). """
        ann = open('data/{}.ann'.format(filename))

        # build a dictionary for annotations
        d = {}
        for l in ann.readlines():
            k, v = l.split()[2:4]
            d[k] = int(v) - int(k)

        # generate a training file based on the annotations.
        f = open('data/{}.txt'.format(filename))
        lines = f.readlines()
        corpus = "".join(lines)
        # punctuation-based tokenization
        spans = WordPunctTokenizer().span_tokenize(corpus)
        train_corpus = ""
        gene_end = 0

        for span in spans:
            s, e = span  # span
            tok = corpus[s:e]
            if d.get(str(s)):
                gene_end = s + int(d.get(str(s)))
                train_corpus += '{} GENE\n'.format(self.fb.generate(tok))
            elif e <= gene_end:
                train_corpus += '{} GENE\n'.format(self.fb.generate(tok))
            else:
                if tok == ".":
                    train_corpus += '{} O\n\n'.format(tok)
                else:
                    train_corpus += '{} O\n'.format(self.fb.generate(tok))

        o = open('data/{}.trn'.format(filename), 'w')
        o.write(train_corpus)
        return train_corpus

    def testing(self, filename):
        """ Generate a test file (file_basename.tst) in data/ directory. """
        f = open('data/{}.txt'.format(filename))
        lines = f.readlines()
        corpus = "".join(lines)
        spans = WordPunctTokenizer().span_tokenize(corpus)
        test_corpus = ""

        for span in spans:
            s, e = span  # span
            tok = corpus[s:e]
            if tok is ".":  # TODO: better algorithm for sentence detection
                test_corpus += '{}\n\n'.format(tok)
            else:
                test_corpus += '{}\n'.format(self.fb.generate(tok))

        o = open('data/{}.tst'.format(filename), 'w')
        o.write(test_corpus)

        return test_corpus


if __name__ == "__main__":
    pass  # TODO: a placeholder for tests.

#